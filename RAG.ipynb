{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef075781-834b-40b0-9a6e-6424ac07ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686ebbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7050e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader('sentiment.csv')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafdc73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=0)\n",
    "documents = doc_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66a9a36-9c31-4c2d-9025-014f693a723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asinghal/PycharmProjects/Capstone/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/asinghal/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "llm_model = HuggingFaceEndpoint(repo_id='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "                                huggingfacehub_api_token='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',\n",
    "                                temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c666687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asinghal/PycharmProjects/Capstone/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "chain = ConversationalRetrievalChain.from_llm(llm=llm_model, retriever=vectorstore.as_retriever(search_kwargs={'k':20}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ba2e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the average number of retweets? Take the entire dataset to answer this question', 'chat_history': [], 'answer': \" To calculate the average number of retweets, we need to add up all the retweets and then divide by the total number of posts. Let's do that!\\n\\nFirst, let's add up all the retweets:\\n\\n135 + 25 + 25 + 25 + 14 + 30 + 30 + 22 + 30 + 18 + 24 + 15 + 15 + 17 + 20 + 17 + 15 + 25 + 30 + 25 + 25 + 30 + 30 + 18 + 23 + 15 + 20 + 15 + 17 + 30 + 60 + 25 + 25 + 30 + 30 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + 25 + \"}\n"
     ]
    }
   ],
   "source": [
    "query = 'What is the average number of retweets? Take the entire dataset to answer this question'\n",
    "response = chain.invoke({'question': query, 'chat_history': []})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
