{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.tools import BaseTool\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_csv('sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª          ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text    Sentiment  \\\n",
       "0           0   Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1           1   Traffic was terrible this morning.           ...   Negative     \n",
       "2           2   Just finished an amazing workout! ðŸ’ª          ...   Positive     \n",
       "3           3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4           4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "\n",
       "             Timestamp            User     Platform  \\\n",
       "0  2023-01-15 12:30:00   User123          Twitter     \n",
       "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
       "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
       "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
       "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
       "\n",
       "                                     Hashtags  Retweets  Likes       Country  \\\n",
       "0   #Nature #Park                                  15.0   30.0     USA         \n",
       "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
       "2   #Fitness #Workout                              20.0   40.0   USA           \n",
       "3   #Travel #Adventure                              8.0   15.0     UK          \n",
       "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans the input text by performing several steps:\n",
    "    - Removing special characters and digits\n",
    "    - Converting text to lowercase\n",
    "    - Removing stopwords\n",
    "    - Lemmatizing the words\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned text.\n",
    "    \"\"\"\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans the input DataFrame by performing several common data cleaning steps:\n",
    "    - Handling missing values\n",
    "    - Correcting data types\n",
    "    - Removing duplicates\n",
    "    - Normalizing column names\n",
    "    - Cleaning text data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame to clean.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Remove any duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Step 2: Handle missing values\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            # Fill missing text data with an empty string\n",
    "            df[column] = df[column].fillna('')\n",
    "        else:\n",
    "            # Fill missing numeric data with the mean\n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "\n",
    "    # Step 3: Correct data types\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            try:\n",
    "                df[column] = pd.to_datetime(df[column])\n",
    "            except (ValueError, TypeError):\n",
    "                pass  # If conversion to datetime fails, we keep the original dtype\n",
    "\n",
    "    # Step 4: Normalize column names\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    # Step 5: Clean text data\n",
    "    for column in df.select_dtypes(include=['object']).columns:\n",
    "        df[column] = df[column].apply(clean_text)\n",
    "    \n",
    "    # Step 6: (Optional) Remove outliers\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        filter = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n",
    "        df = df.loc[filter]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xp/r07slbbd11v896_crn62zqx40000gp/T/ipykernel_97020/2658688072.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n",
      "/var/folders/xp/r07slbbd11v896_crn62zqx40000gp/T/ipykernel_97020/2658688072.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n",
      "/var/folders/xp/r07slbbd11v896_crn62zqx40000gp/T/ipykernel_97020/2658688072.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n",
      "/var/folders/xp/r07slbbd11v896_crn62zqx40000gp/T/ipykernel_97020/2658688072.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n",
      "/var/folders/xp/r07slbbd11v896_crn62zqx40000gp/T/ipykernel_97020/2658688072.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n",
      "/var/folders/xp/r07slbbd11v896_crn62zqx40000gp/T/ipykernel_97020/2658688072.py:33: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed:_0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>platform</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>enjoying beautiful day park</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>user</td>\n",
       "      <td>twitter</td>\n",
       "      <td>nature park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>finished amazing workout</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>fitnessfan</td>\n",
       "      <td>instagram</td>\n",
       "      <td>fitness workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>excited upcoming weekend getaway</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>adventurex</td>\n",
       "      <td>facebook</td>\n",
       "      <td>travel adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>uk</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>trying new recipe dinner tonight</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>chefcook</td>\n",
       "      <td>instagram</td>\n",
       "      <td>cooking food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>feeling grateful little thing life</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-01-16 09:10:00</td>\n",
       "      <td>gratitudenow</td>\n",
       "      <td>twitter</td>\n",
       "      <td>gratitude positivevibes</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>india</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>727</td>\n",
       "      <td>collaborating science project received recogni...</td>\n",
       "      <td>happy</td>\n",
       "      <td>2017-08-18 18:20:00</td>\n",
       "      <td>scienceprojectsuccesshighschool</td>\n",
       "      <td>facebook</td>\n",
       "      <td>sciencefairwinner highschoolscience</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>uk</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>728</td>\n",
       "      <td>attending surprise birthday party organized fr...</td>\n",
       "      <td>happy</td>\n",
       "      <td>2018-06-22 14:15:00</td>\n",
       "      <td>birthdaypartyjoyhighschool</td>\n",
       "      <td>instagram</td>\n",
       "      <td>surprisecelebration highschoolfriendship</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>729</td>\n",
       "      <td>successfully fundraising school charity initia...</td>\n",
       "      <td>happy</td>\n",
       "      <td>2019-04-05 17:30:00</td>\n",
       "      <td>charityfundraisingtriumphhighschool</td>\n",
       "      <td>twitter</td>\n",
       "      <td>communitygiving highschoolphilanthropy</td>\n",
       "      <td>22.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>canada</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>730</td>\n",
       "      <td>participating multicultural festival celebrati...</td>\n",
       "      <td>happy</td>\n",
       "      <td>2020-02-29 20:45:00</td>\n",
       "      <td>multiculturalfestivaljoyhighschool</td>\n",
       "      <td>facebook</td>\n",
       "      <td>culturalcelebration highschoolunity</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>uk</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>731</td>\n",
       "      <td>organizing virtual talent show challenging tim...</td>\n",
       "      <td>happy</td>\n",
       "      <td>2020-11-15 15:15:00</td>\n",
       "      <td>virtualtalentshowsuccesshighschool</td>\n",
       "      <td>instagram</td>\n",
       "      <td>virtualentertainment highschoolpositivity</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unnamed:_0                                               text sentiment  \\\n",
       "0             0                        enjoying beautiful day park  positive   \n",
       "2             2                           finished amazing workout  positive   \n",
       "3             3                   excited upcoming weekend getaway  positive   \n",
       "4             4                   trying new recipe dinner tonight   neutral   \n",
       "5             5                 feeling grateful little thing life  positive   \n",
       "..          ...                                                ...       ...   \n",
       "727         727  collaborating science project received recogni...     happy   \n",
       "728         728  attending surprise birthday party organized fr...     happy   \n",
       "729         729  successfully fundraising school charity initia...     happy   \n",
       "730         730  participating multicultural festival celebrati...     happy   \n",
       "731         731  organizing virtual talent show challenging tim...     happy   \n",
       "\n",
       "              timestamp                                 user   platform  \\\n",
       "0   2023-01-15 12:30:00                                 user    twitter   \n",
       "2   2023-01-15 15:45:00                           fitnessfan  instagram   \n",
       "3   2023-01-15 18:20:00                           adventurex   facebook   \n",
       "4   2023-01-15 19:55:00                             chefcook  instagram   \n",
       "5   2023-01-16 09:10:00                         gratitudenow    twitter   \n",
       "..                  ...                                  ...        ...   \n",
       "727 2017-08-18 18:20:00      scienceprojectsuccesshighschool   facebook   \n",
       "728 2018-06-22 14:15:00           birthdaypartyjoyhighschool  instagram   \n",
       "729 2019-04-05 17:30:00  charityfundraisingtriumphhighschool    twitter   \n",
       "730 2020-02-29 20:45:00   multiculturalfestivaljoyhighschool   facebook   \n",
       "731 2020-11-15 15:15:00   virtualtalentshowsuccesshighschool  instagram   \n",
       "\n",
       "                                      hashtags  retweets  likes    country  \\\n",
       "0                                  nature park      15.0   30.0        usa   \n",
       "2                              fitness workout      20.0   40.0        usa   \n",
       "3                             travel adventure       8.0   15.0         uk   \n",
       "4                                 cooking food      12.0   25.0  australia   \n",
       "5                      gratitude positivevibes      25.0   50.0      india   \n",
       "..                                         ...       ...    ...        ...   \n",
       "727        sciencefairwinner highschoolscience      20.0   39.0         uk   \n",
       "728   surprisecelebration highschoolfriendship      25.0   48.0        usa   \n",
       "729     communitygiving highschoolphilanthropy      22.0   42.0     canada   \n",
       "730        culturalcelebration highschoolunity      21.0   43.0         uk   \n",
       "731  virtualentertainment highschoolpositivity      24.0   47.0        usa   \n",
       "\n",
       "     year  month  day  hour  \n",
       "0    2023      1   15    12  \n",
       "2    2023      1   15    15  \n",
       "3    2023      1   15    18  \n",
       "4    2023      1   15    19  \n",
       "5    2023      1   16     9  \n",
       "..    ...    ...  ...   ...  \n",
       "727  2017      8   18    18  \n",
       "728  2018      6   22    14  \n",
       "729  2019      4    5    17  \n",
       "730  2020      2   29    20  \n",
       "731  2020     11   15    15  \n",
       "\n",
       "[698 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = clean_data(sentiment_df)\n",
    "\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameTool(BaseTool):\n",
    "    name = \"DataFrameTool\"\n",
    "    description = \"A tool that takes a Pandas DataFrame, performs operations and returns a new DataFrame.\"\n",
    "\n",
    "    def _run(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        cleaned_data = clean_data(df)\n",
    "        return cleaned_data\n",
    "    \n",
    "    def _call(self, df):\n",
    "        return self._run(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = ChatGroq(temperature=0, groq_api_key='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', model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "agent_with_tool = create_pandas_dataframe_agent(llm=llm_model, df=sentiment_df,verbose=True, agent_type='tool-calling', extra_tools=[DataFrameTool()])\n",
    "\n",
    "agent_without_tool = create_pandas_dataframe_agent(llm=llm_model, df=sentiment_df,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_without_tool.invoke('Take the dataset and preprocess it using the tools available to you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_tool.invoke('Take the dataset and preprocess it using the tools available to you')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
